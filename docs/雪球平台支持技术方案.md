以下是“扩展雪球平台支持”方案文档，包含目标、实现步骤、核心代码设计和后续验证指引，供审核后再进入开发阶段。

---

## 1. 目标概述
- 在 **DeepSentimentCrawling** 模块中新增 `xueqiu` 平台，使其与现有 7 个平台在 CLI、配置、日志、数据库写入等方面保持一致。
- 复用 MediaCrawler 的框架（Playwright + HTTP Client + Store）完成雪球的登录、搜索、详情抓取与数据落库。
- 更新 README/文档与平台枚举，确保命令行参数 `--platform xueqiu` 可直接使用。

---

## 2. 实现步骤

### 步骤一：基础配置与 CLI 扩展
1. **平台枚举**  
   - 更新 [DeepSentimentCrawling/platforms_config.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/platforms_config.py:0:0-0:0)：`SUPPORTED_PLATFORMS` 增加 `"xueqiu"`。  
   - 更新 [MediaCrawler/cmd_arg/arg.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/cmd_arg/arg.py:0:0-0:0) 的 [PlatformEnum](cci:2://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/cmd_arg/arg.py:29:0-38:19)，新增 `XUEQIU = "xueqiu"`，并在 `--platform` 帮助文案列出。  
2. **日志与配置说明**  
   - `logging_utils.PLATFORM_NAME_MAP` 增加 `"xueqiu": "xueqiu"`，确保单独日志文件生成。  
   - [MediaCrawler/config/base_config.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/config/base_config.py:0:0-0:0) 中 `PLATFORM` 注释补充雪球；若需要手机号、Cookie 配置，预留 `XUEQIU_*` 字段。  
3. **命令示例**  
   - README（项目根 & MediaCrawler）增加雪球的运行命令示例，说明登录方式、支持的 `crawler_type`。

### 步骤二：雪球平台爬虫实现
1. **目录与核心文件**  
   - `MediaCrawler/media_platform/xueqiu/`（若不存在则新建）内创建：
     - [__init__.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/config/__init__.py:0:0-0:0)
     - `core.py`：派生自 `base.base_crawler.AbstractCrawler`，负责调度 Playwright + HTTP 客户端，执行 `search/detail/creator` 对应逻辑。
     - [login.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/media_platform/xhs/login.py:0:0-0:0)：派生自 `base.base_crawler.AbstractLogin`，支持 `qrcode`（扫描网页登录）、`phone`（短信验证码）、`cookie` 三种模式。
     - [client.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/media_platform/xhs/client.py:0:0-0:0)：封装雪球开放/私有 API 请求（HTTPX），提供 [pong()](cci:1://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/media_platform/xhs/client.py:177:4-195:24)、`search_notes()`、`get_note_detail()` 等方法。
     - `crawler.py`（或拆分 `search.py` 等）：根据关键字遍历笔记/帖子，落地内容与评论。
2. **登录实现要点**  
   - **二维码**：访问 `https://xueqiu.com/`，等待二维码元素（若网页逻辑允许），使用 `utils.find_login_qrcode` 显示；轮询 cookies 中 `xq_a_token`/`u` 判断登录状态。  
   - **手机号**：与小红书类似，等待手机号登录入口，发送验证码后从缓存读取 `xq_<phone>` 键值。  
   - **Cookie**：支持 `config.COOKIES` 注入 `xq_a_token` 及 `u` 等字段。  
3. **爬虫逻辑**  
   - **search**：调用雪球搜索接口（如 `https://xueqiu.com/query/v1/search/status.json`），按关键词分页抓取帖子（需设置 UA、Referer、xq_a_token）。  
   - **detail/comment**：针对帖子 ID 调用 `https://xueqiu.com/statuses/show.json`、`https://xueqiu.com/statuses/comments.json`。  
   - **creator**：可复用 search 部分数据（后续迭代可增强）。  
   - 统一调用 [store](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/store:0:0-0:0) 目录下的 DAO（如 `store.note_store`）写库，遵循 `config.SAVE_DATA_OPTION`。

### 步骤三：配置与存储适配
1. **配置字段**  
   - 若雪球需要额外参数（如 `LOGIN_PHONE`、`NEED_CAPTCHA`），在 [base_config.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/config/base_config.py:0:0-0:0) 中以可选项形式写入，并在 [config/__init__.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/config/__init__.py:0:0-0:0) 中导出。  
2. **数据库写入**  
   - 检查 [store](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/store:0:0-0:0) 层是否需要新增表或字段（如雪球特有的 `quote_count`）。若需要：
     - 更新 `MediaCrawler/store/models.py` & [schema/](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/schema:0:0-0:0) SQL。  
     - 若 MindSpider 主库要使用，需保证结构兼容（通过 `SAVE_DATA_OPTION=db/postgresql` 写入统一表）。  

### 步骤四：测试与文档
1. **本地验证**  
   - `python main.py --deep-sentiment --platforms xueqiu --test --date YYYY-MM-DD`  
   - 观察 `logs/xueqiu.log`、数据库 `media_notes`/`media_comments` 是否写入记录。  
2. **文档更新**  
   - 项目根 README：在“平台登录配置”“运行命令示例”处新增雪球章节。  
   - [MediaCrawler/README.md](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/DeepSentimentCrawling/MediaCrawler/README.md:0:0-0:0)：新增雪球专栏（登录方式、接口限制、常见风控提示）。  
   - 若新增配置项，更新 `.env.example`、[config.py](cci:7://file:///d:/Python-Learning/bettafish/MindSpider/config.py:0:0-0:0) 文档说明。

---

## 3. 核心代码设计示例

### 3.1 CLI 枚举扩展
```python
# -*- coding: utf-8 -*-
# MediaCrawler/cmd_arg/arg.py
class PlatformEnum(str, Enum):
    XHS = "xhs"
    DOUYIN = "dy"
    KUAISHOU = "ks"
    BILIBILI = "bili"
    WEIBO = "wb"
    TIEBA = "tieba"
    ZHIHU = "zhihu"
    XUEQIU = "xueqiu"  # ✅ 新增雪球
```

### 3.2 雪球核心入口
```python
# -*- coding: utf-8 -*-
"""
雪球平台爬虫入口
"""
from base.base_crawler import AbstractCrawler
from tools import utils
import config

class XueQiuCrawler(AbstractCrawler):
    """雪球平台爬虫"""
    def __init__(self):
        super().__init__()
        self.index_url = "https://xueqiu.com/"
        self.search_api = "https://xueqiu.com/query/v1/search/status.json"
        self.detail_api = "https://xueqiu.com/statuses/show.json"
        self.comment_api = "https://xueqiu.com/statuses/comments.json"
        self.user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64)..."

    async def start(self):
        utils.logger.info("[XueQiuCrawler] 启动雪球爬虫")
        await self.bootstrap_browser(headless=config.HEADLESS)
        login_client = XueQiuLogin(
            login_type=config.LOGIN_TYPE,
            browser_context=self.browser_context,
            context_page=self.context_page,
            login_phone=config.LOGIN_PHONE,
            cookie_str=config.COOKIES,
        )
        if not await self.api_client.pong():
            await login_client.begin()
            await self.api_client.update_cookies(browser_context=self.browser_context)
        if config.CRAWLER_TYPE == "search":
            await self.search()
        elif config.CRAWLER_TYPE == "detail":
            await self.get_specified_notes()
        elif config.CRAWLER_TYPE == "creator":
            await self.get_creators_and_notes()
        utils.logger.info("[XueQiuCrawler] 任务完成")
```

### 3.3 雪球搜索逻辑示例
```python
# -*- coding: utf-8 -*-
"""雪球搜索爬虫逻辑"""
import asyncio
from typing import Dict, List
from tools import utils
import config

class XueQiuSearchMixin:
    async def search(self) -> None:
        utils.logger.info("[XueQiuCrawler.search] 开始搜索雪球帖子")
        keywords = config.KEYWORDS.split(",")
        for keyword in keywords:
            await self._search_single_keyword(keyword.strip())

    async def _search_single_keyword(self, keyword: str) -> None:
        utils.logger.info(f"[XueQiuCrawler.search] 关键词: {keyword}")
        page = 1
        notes_count = 0
        while notes_count < config.CRAWLER_MAX_NOTES_COUNT:
            resp = await self.api_client.search_status(
                keyword=keyword, page=page, page_size=20
            )
            items = resp.get("list", [])
            if not items:
                utils.logger.info("[XueQiuCrawler.search] 没有更多结果，停止")
                break
            for item in items:
                await self.note_store.save_xueqiu_note(item, keyword=keyword)
                notes_count += 1
                if notes_count >= config.CRAWLER_MAX_NOTES_COUNT:
                    break
            page += 1
            await asyncio.sleep(config.CRAWLER_MAX_SLEEP_SEC)
        utils.logger.info(f"[XueQiuCrawler.search] {keyword} 完成，共 {notes_count} 条")
```

### 3.4 登录流程（二维码示例）
```python
# -*- coding: utf-8 -*-
import asyncio
import functools
from base.base_crawler import AbstractLogin
from tools import utils

class XueQiuLogin(AbstractLogin):
    async def login_by_qrcode(self):
        utils.logger.info("[XueQiuLogin.qrcode] 打开雪球首页")
        await self.context_page.goto("https://xueqiu.com/")
        qrcode_selector = "xpath=//*[@class='login-modal']//img[contains(@src,'qrcode')]"
        qrcode = await utils.find_login_qrcode(self.context_page, selector=qrcode_selector)
        if not qrcode:
            utils.logger.error("[XueQiuLogin.qrcode] 未找到二维码")
            return
        asyncio.get_running_loop().run_in_executor(
            None, functools.partial(utils.show_qrcode, qrcode)
        )
        await self._wait_login_cookie()

    async def _wait_login_cookie(self):
        max_retry = 120
        while max_retry > 0:
            cookies, cookie_dict = await utils.convert_cookies(await self.browser_context.cookies())
            if cookie_dict.get("xq_a_token") and cookie_dict.get("u"):
                utils.logger.info("[XueQiuLogin] 登录成功")
                return
            max_retry -= 1
            await asyncio.sleep(1)
        raise RuntimeError("二维码登录超时")
```

---

## 4. 验证与交付清单
- ✅ CLI `--platform xueqiu` 可执行，`SUPPORTED_PLATFORMS` 与日志模块同步。  
- ✅ `python main.py --deep-sentiment --platforms xueqiu --test` 正常跑通；`logs/xueqiu.log` 独立输出。  
- ✅ 数据写入 MySQL/PostgreSQL 与已有表兼容/或新增表结构且 README 说明。  
- ✅ README/MediaCrawler 文档新增雪球章节，说明登录方式与命令示例。  
- ✅ `.env.example`（若新增配置）已同步。

---

确认方案后，我将按上述步骤依次实现，并在关键节点更新 TODO/计划。请指示是否可以按此方案推进。